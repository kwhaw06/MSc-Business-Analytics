{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T21:30:20.622803Z",
     "start_time": "2021-05-21T21:30:20.176879Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T21:30:20.638761Z",
     "start_time": "2021-05-21T21:30:20.628820Z"
    }
   },
   "outputs": [],
   "source": [
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract discussions link for each forum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T21:30:20.653853Z",
     "start_time": "2021-05-21T21:30:20.641752Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function that extract all discussions under a brand's forum\n",
    "\n",
    "def get_dis_link(brand, page=1):\n",
    "    \n",
    "    url = f'{brand}page-{page}'\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    dis_link = soup.find_all('div', {'class':'structItem-title'})\n",
    "    \n",
    "    for item in dis_link:\n",
    "\n",
    "        # Discussion link\n",
    "        link = 'https://www.speakev.com' + item.find('a', {'data-tp-primary': 'on'})['href']  \n",
    "        \n",
    "        # Append link to list\n",
    "        dis_link_list.append(link)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T21:30:21.695887Z",
     "start_time": "2021-05-21T21:30:20.655799Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fiat \n",
    "brand = 'https://www.speakev.com/forums/fiat-500.361/'\n",
    "dis_link_list = []\n",
    "\n",
    "get_dis_link(brand)\n",
    "\n",
    "fiat_dislist = dis_link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T21:30:23.523144Z",
     "start_time": "2021-05-21T21:30:21.697888Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mini\n",
    "brand = 'https://www.speakev.com/forums/mini.300/'\n",
    "page_num = 2 \n",
    "dis_link_list = []\n",
    "\n",
    "for page in range(1, page_num+1):\n",
    "    get_dis_link(brand, page)\n",
    "\n",
    "mini_dislist = dis_link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T21:47:37.203837Z",
     "start_time": "2021-05-21T21:47:37.189875Z"
    }
   },
   "outputs": [],
   "source": [
    "# competitor 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T21:47:40.365653Z",
     "start_time": "2021-05-21T21:47:40.360696Z"
    }
   },
   "outputs": [],
   "source": [
    "# competitor 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of pages in each discussion post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T21:45:29.134106Z",
     "start_time": "2021-05-21T21:45:29.117180Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function that extracts the number of pages in a discussion post\n",
    "\n",
    "def get_dis_pagenum(url, page=1):\n",
    "    \n",
    "    url = f'{url}page-{page}'\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    dis_link = soup.find_all('div', {'class':'reply-count'})\n",
    "    \n",
    "    ####################################\n",
    "    ## Extract discussion page number ##\n",
    "    ####################################\n",
    "    \n",
    "    for i in dis_link:\n",
    "        \n",
    "        num = i.text\n",
    "        # Convert all value with 'K' into 000s\n",
    "        num = num.replace('K','000')\n",
    "        \n",
    "        if int(num) <= 20:\n",
    "            num_list.append(1)\n",
    "            \n",
    "        else:\n",
    "            x = int(num)/20\n",
    "            num_list.append(round(int(x+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T21:45:30.617365Z",
     "start_time": "2021-05-21T21:45:29.573364Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fiat\n",
    "url = 'https://www.speakev.com/forums/fiat-500.361/'\n",
    "num_list = []\n",
    "\n",
    "get_dis_pagenum(url)\n",
    "\n",
    "# merge both lists into a dict\n",
    "fiat_dis_page = dict(zip(fiat_dislist, num_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T21:45:32.656393Z",
     "start_time": "2021-05-21T21:45:30.836993Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mini\n",
    "url = 'https://www.speakev.com/forums/mini.300/'\n",
    "page_num = 2 \n",
    "num_list = []\n",
    "\n",
    "for page in range(1, page_num+1):\n",
    "    get_dis_pagenum(url, page)\n",
    "\n",
    "# merge both lists into # competitor 3\n",
    "\n",
    "# competitor 4a dict\n",
    "mini_dis_page = dict(zip(mini_dislist, num_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T21:47:37.203837Z",
     "start_time": "2021-05-21T21:47:37.189875Z"
    }
   },
   "outputs": [],
   "source": [
    "# competitor 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T21:47:40.365653Z",
     "start_time": "2021-05-21T21:47:40.360696Z"
    }
   },
   "outputs": [],
   "source": [
    "# competitor 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract date of comment and comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T21:49:48.655406Z",
     "start_time": "2021-05-21T21:49:48.640413Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function that extract date of comment and comment\n",
    "\n",
    "def get_comment_and_date(tag, page=0):\n",
    "    \n",
    "    url = f'https://www.speakev.com/threads/{tag}/page-{page}'\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    ##############################\n",
    "    ## Extract date and comment ##\n",
    "    ##############################\n",
    "   \n",
    "    message_cell = soup.find_all('div', {'class':'js-quickEditTarget message-cell-content-wrapper'})\n",
    "    \n",
    "    for item in message_cell:\n",
    "        \n",
    "        info1 = {\n",
    "        'comment date' : item.find('time', {'class':'u-dt'})['datetime'],\n",
    "        'comment' : item.find('div', {'class':'bbWrapper'}).text.replace('\\n',''), \n",
    "        }\n",
    "        \n",
    "        list1.append(info1)\n",
    "        \n",
    "    #########################\n",
    "    ## Extract user detail ##\n",
    "    #########################\n",
    "    \n",
    "    message_userDetails = soup.find_all('div', {'class':'message-userDetails'})\n",
    "    \n",
    "    for item in message_userDetails:\n",
    "    \n",
    "        # User link\n",
    "        link = 'https://www.speakev.com' + item.find('a', {'class': 'username'})['href'] \n",
    "        \n",
    "        info2 = {\n",
    "            'author url' : link\n",
    "        }\n",
    "        \n",
    "        list2.append(info2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
